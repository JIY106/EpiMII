{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7448022f-78ba-40c6-be4e-8d53999d6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#generate a txt file that only contain the cluster number (from 1 to 142934)\n",
    "content = \"\\n\".join(str(i) for i in range(1, 142935)) #total number of epitopes\n",
    "with open(\"clusters.txt\", \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1376871e-5f3a-4807-9f95-2904246b00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read clusters from file\n",
    "with open(\"clusters.txt\", \"r\") as file:\n",
    "    data = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a906c19e-8e45-4616-bf80-c59a53f3f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated split_dataset function\n",
    "def split_dataset(data, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must add up to 1.0\"\n",
    "    random.seed(42)\n",
    "    random.shuffle(data)\n",
    "    total_size = len(data)\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "    # No need to calculate test_size; it's determined by subtracting train and val sizes\n",
    "\n",
    "    train_set = data[:train_size]\n",
    "    val_set = data[train_size:train_size + val_size]\n",
    "    test_set = data[train_size + val_size:]  # This automatically takes the remaining portion\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38312b5-07e0-4697-91e7-3dd30af86b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated save_dataset_to_txt function\n",
    "def save_dataset_to_txt(data, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for item in data:\n",
    "            file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9ebd36-bbd3-4e5d-82c4-04fca99c6890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 114347\n",
      "Validation size: 14293\n",
      "Test size: 14294\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "train_set, val_set, test_set = split_dataset(data)\n",
    "\n",
    "# Saving the datasets\n",
    "save_dataset_to_txt(train_set, 'train.txt')\n",
    "save_dataset_to_txt(val_set, 'validation.txt')\n",
    "save_dataset_to_txt(test_set, 'test.txt')\n",
    "\n",
    "# Printing sizes\n",
    "print(\"Train size:\", len(train_set))\n",
    "print(\"Validation size:\", len(val_set))\n",
    "print(\"Test size:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa7139-c872-4d3b-8106-b4080ba0a275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
