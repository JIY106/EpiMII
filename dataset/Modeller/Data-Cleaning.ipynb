{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc8f449-40ed-4646-a338-4b575a101dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate haha file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99709c4-1ef3-4405-9b51-0da7244f8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output file paths\n",
    "input_file_path = 'output1.txt' #generate by CalculateSimilarityAndSave.py\n",
    "output_file_path = 'haha.txt'\n",
    "\n",
    "# Open the input file for reading\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    # Read lines from the input file\n",
    "    lines = input_file.readlines()\n",
    "\n",
    "# Open the output file for writing\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    # Iterate through the lines read from the input file\n",
    "    for line_index in range(0, len(lines), 3):\n",
    "        # Extract relevant information from each group of three lines\n",
    "        pdb_name = lines[line_index].strip()\n",
    "        template_line = lines[line_index + 1]\n",
    "        similarity_line = lines[line_index + 2]\n",
    "\n",
    "        # Extract template name and similarity from the corresponding lines\n",
    "        template_name = template_line.split(': ')[1].strip()\n",
    "        similarity = float(similarity_line.split(': ')[1].strip()[:-1])  # Remove '%' and convert to float\n",
    "\n",
    "        # Check if the similarity is greater than or equal to 30%\n",
    "        if similarity >= 10.0:\n",
    "            # Write the pdb name and its corresponding template name and similarity to the output file\n",
    "            output_line = f\"{pdb_name},{template_name},{similarity}%\\n\"\n",
    "            output_file.write(output_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba697821-3236-4022-956e-e484b0910bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items processed: 5\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output file paths\n",
    "input_file_path = 'output1.txt'\n",
    "output_file_path = 'haha.txt'\n",
    "\n",
    "# Counter for the number of items processed\n",
    "num_items_processed = 0\n",
    "\n",
    "# Open the input file for reading\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    # Read lines from the input file\n",
    "    lines = input_file.readlines()\n",
    "\n",
    "    # Open the output file for writing\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        # Iterate through the lines read from the input file\n",
    "        for line_index in range(0, len(lines), 3):\n",
    "            # Extract relevant information from each group of three lines\n",
    "            pdb_name = lines[line_index].strip()\n",
    "            template_line = lines[line_index + 1]\n",
    "            similarity_line = lines[line_index + 2]\n",
    "\n",
    "            # Extract template name and similarity from the corresponding lines\n",
    "            template_name = template_line.split(': ')[1].strip()\n",
    "            similarity = float(similarity_line.split(': ')[1].strip()[:-1])  # Remove '%' and convert to float\n",
    "\n",
    "            # Check if the similarity is greater than or equal to 30%\n",
    "            if similarity >= 25.0:\n",
    "                # Write the pdb name and its corresponding template name and similarity to the output file\n",
    "                output_line = f\"{pdb_name},{template_name},{similarity}%\\n\"\n",
    "                output_file.write(output_line)\n",
    "\n",
    "            # Increment the counter for the number of items processed every three lines\n",
    "            num_items_processed += 1\n",
    "\n",
    "# Print the number of items processed\n",
    "print(f\"Number of items processed: {num_items_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1857fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following codes are used to select 25% seq similarity, delete the duplicated one and build the model with Build-model3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098f72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "haha_file_path = 'haha.txt'\n",
    "fasta_file_path = 'DB_clu_seq.fasta' #your fasta file\n",
    "output_file_path = 'ID_sequence_list.txt'\n",
    "\n",
    "# Read IDs from haha_28.txt\n",
    "with open(haha_file_path, 'r') as haha_file:\n",
    "    ids = [line.split(',')[0] for line in haha_file]\n",
    "\n",
    "# Search for sequences in DB_clu_seq.fasta and save them to ID_sequence_list1.txt\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    with open(fasta_file_path, 'r') as fasta_file:\n",
    "        lines = fasta_file.readlines()\n",
    "        current_id = None\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                current_id = line[1:]\n",
    "            elif current_id in ids:\n",
    "                output_file.write(f'{current_id}\\n{line}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448670b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined sequences have been saved to 'combined_output1.txt'\n"
     ]
    }
   ],
   "source": [
    "# Open the original file for reading\n",
    "with open('ID_sequence_list.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Combine every two lines with a comma between them\n",
    "combined_lines = []\n",
    "for i in range(0, len(lines), 2):\n",
    "    combined_lines.append(f\"{lines[i].strip()},{lines[i+1].strip()}\")\n",
    "\n",
    "# Write the combined lines into a new file\n",
    "with open('combined_output1.txt', 'w') as file:\n",
    "    for line in combined_lines:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "print(\"Combined sequences have been saved to 'combined_output1.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debe79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"combined_output1.txt\"\n",
    "output_file = \"combined_output1.csv\"\n",
    "\n",
    "# Read data from the input file and write to CSV\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    reader = csv.reader(infile, delimiter=',')\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in reader:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0037f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN EXCEL SORT THE SEQUENCE FROM Z-A and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee68aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous ID: 1786762\n",
      "Previous Sequence: LIEFRRIAAYLFKG\n",
      "Current ID: 83675\n",
      "Current Sequence: ILLGSHKDSDVPSCP\n",
      "Current ID: 83582\n",
      "Current Sequence: IKDVLKYRWLNLSAN\n",
      "Current ID: 83451\n",
      "Current Sequence: IGHHVELQHIILNAS\n",
      "Current ID: 83269\n",
      "Current Sequence: HVFEENLIGLIGRGG\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the previous sequence and ID\n",
    "prev_id = None\n",
    "prev_sequence = None\n",
    "\n",
    "# Lists to store duplicated and non-duplicated sequences\n",
    "duplicated_sequences = []\n",
    "non_duplicated_sequences = []\n",
    "\n",
    "input_file = \"combined_output1.csv\"\n",
    "\n",
    "# Open the input file\n",
    "with open(input_file, 'r') as infile:\n",
    "    # Read the first line to initialize prev_id and prev_sequence\n",
    "    first_line = infile.readline().strip().split(',')\n",
    "    if len(first_line) >= 2:\n",
    "        prev_id, prev_sequence = first_line[0], first_line[1]\n",
    "        print(\"Previous ID:\", prev_id)\n",
    "        print(\"Previous Sequence:\", prev_sequence)\n",
    "        # Add the first line to non_duplicated_sequences**\n",
    "        non_duplicated_sequences.append(first_line) \n",
    "\n",
    "    # Continue reading the rest of the lines\n",
    "    for line in infile:\n",
    "        line = line.strip().split(',')  # Split the line by comma (',')\n",
    "\n",
    "        # Check if the line contains at least two elements\n",
    "        if len(line) >= 2:\n",
    "            current_id, current_sequence = line[0], line[1]\n",
    "            print(\"Current ID:\", current_id)\n",
    "            print(\"Current Sequence:\", current_sequence)\n",
    "            \n",
    "            # Check if the current sequence is a subset of the previous sequence\n",
    "            if prev_sequence and current_sequence in prev_sequence:\n",
    "                duplicated_sequences.append(line)\n",
    "            else:\n",
    "                non_duplicated_sequences.append(line)\n",
    "            \n",
    "            # Update the previous ID and sequence for the next iteration\n",
    "            prev_id = current_id\n",
    "            prev_sequence = current_sequence\n",
    "\n",
    "# Write duplicated sequences to a file\n",
    "with open('duplicated_sequences.txt', 'w') as dup_file:\n",
    "    for line in duplicated_sequences:\n",
    "        dup_file.write(','.join(line) + '\\n')\n",
    "\n",
    "# Write non-duplicated sequences to a file\n",
    "with open('non_duplicated_sequences.txt', 'w') as non_dup_file:\n",
    "    for line in non_duplicated_sequences:\n",
    "        non_dup_file.write(','.join(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce22dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filenames\n",
    "non_duplicated_file = \"non_duplicated_sequences.txt\"\n",
    "haha_30_file = \"haha.txt\"\n",
    "output_file = \"combined_output1.txt\"\n",
    "\n",
    "# Create dictionaries to store sequences and templates\n",
    "sequences_dict = {}\n",
    "templates_dict = {}\n",
    "\n",
    "# Read non-duplicated sequences file\n",
    "with open(non_duplicated_file, 'r') as seq_file:\n",
    "    for line in seq_file:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) == 2:\n",
    "            sequences_dict[parts[0]] = parts[1]\n",
    "\n",
    "# Read haha_30 file\n",
    "with open(haha_30_file, 'r') as haha_file:\n",
    "    for line in haha_file:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) == 3:\n",
    "            templates_dict[parts[0]] = (parts[1], parts[2])\n",
    "\n",
    "# Combine information and write to output file\n",
    "with open(output_file, 'w') as out_file:\n",
    "    for id_, sequence in sequences_dict.items():\n",
    "        if id_ in templates_dict:\n",
    "            template, similarity = templates_dict[id_]\n",
    "            out_file.write(f\"{id_},{template},{sequence},{similarity}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9e5cb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs extracted and saved to extracted_ids.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output file names\n",
    "input_file = \"non_duplicated_sequences.txt\"\n",
    "output_file = \"extracted_ids.txt\"\n",
    "\n",
    "# Open the input file to read IDs\n",
    "with open(input_file, 'r') as infile:\n",
    "    # Open the output file to write extracted IDs\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        # Read each line in the input file\n",
    "        for line in infile:\n",
    "            # Split the line by comma to separate the ID\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) >= 1:\n",
    "                # Write the ID to the output file\n",
    "                outfile.write(parts[0] + '\\n')\n",
    "\n",
    "print(\"IDs extracted and saved to extracted_ids.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81ace9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same method as Fasta2Pir.sh to generate ali files\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the input and output file names\n",
    "input_file = \"non_duplicated_sequences.txt\"\n",
    "output_folder = \"ali1\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Open the input file to read sequences and IDs\n",
    "with open(input_file, 'r') as infile:\n",
    "    # Read each line in the input file\n",
    "    for line in infile:\n",
    "        # Split the line by comma to separate the ID and sequence\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) >= 2:\n",
    "            seq_id, sequence = parts[0], parts[1]\n",
    "\n",
    "            # Create the .ali file path\n",
    "            output_file = os.path.join(output_folder, seq_id + \".ali\")\n",
    "            with open(output_file, 'w') as outfile:\n",
    "                # Write the header to the .ali file\n",
    "                outfile.write(\">P1;\" + seq_id + \"\\n\")\n",
    "                outfile.write(\"sequence:\" + seq_id + \":::::::0.00: 0.00\\n\")\n",
    "                # Write the sequence to the .ali file\n",
    "                outfile.write(sequence + \"\\n\")\n",
    "\n",
    "# Modify the .ali files\n",
    "#for filename in os.listdir(output_folder):\n",
    "    #if filename.endswith(\".ali\"):\n",
    "        #os.system(\"sed -i '${{s/$/*/}}' {}\".format(os.path.join(output_folder, filename)))\n",
    "\n",
    "# Define the folder containing the .ali files\n",
    "ali_folder = \"ali1\"\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(ali_folder):\n",
    "    if filename.endswith(\".ali\"):\n",
    "        file_path = os.path.join(ali_folder, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Append '*' to the end of the last line\n",
    "        lines[-1] = lines[-1].strip() + '*\\n'\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b346987-9ddf-4ff5-b995-6a8de1948888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Build_model3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfe978-8d44-44f0-86ce-8fbbf47f40f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
