{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff23f81-9c4b-4515-8447-8ff374a16145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Try my epitope\n",
    "import json, time, os, sys, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93310bfa-06cb-4ed0-b420-0c1534d070f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Model\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split, Subset\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os.path\n",
    "from protein_mpnn_utils import loss_nll, loss_smoothed, gather_edges, gather_nodes, gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq, tied_featurize, parse_PDB\n",
    "from protein_mpnn_utils import StructureDataset, StructureDatasetPDB, ProteinMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3376c-4321-45c5-ba6c-e2cef717c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "model_name = \"128_earlystop\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9dd6f-79e9-4a21-9055-8e13b0d921d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b87b1-52d9-4944-bb7d-5fa25e4ae6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed=int(np.random.randint(0, high=999, size=1, dtype=int)[0]) #write by my own\n",
    "seed = 37\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086348d1-c7a7-463c-93ca-98b82dcd7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_noise=0.0           # Standard deviation of Gaussian noise to add to backbone atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bbac2-dbe8-4f2c-a548-dcc38d832850",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current working directory: {0}\".format(cwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640499ca-83b6-4c6c-8420-028d692bcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model_weights='.'          \n",
    "hidden_dim = 128\n",
    "num_layers = 3 \n",
    "model_folder_path = path_to_model_weights\n",
    "if model_folder_path[-1] != '/':\n",
    "    model_folder_path = model_folder_path + '/'\n",
    "checkpoint_path = model_folder_path + f'{model_name}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8823ace-acc7-455f-a2ce-41d33ef84b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device) \n",
    "print('Number of edges:', checkpoint['num_edges'])\n",
    "noise_level_print = checkpoint['noise_level']\n",
    "print(f'Training noise level: {noise_level_print}A')\n",
    "model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
    "model.to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf2f54-0793-40ce-bc87-9f6829fe95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "def make_tied_positions_for_homomers(pdb_dict_list):\n",
    "    my_dict = {}\n",
    "    for result in pdb_dict_list:\n",
    "        all_chain_list = sorted([item[-1:] for item in list(result) if item[:9]=='seq_chain']) #A, B, C, ...\n",
    "        tied_positions_list = []\n",
    "        chain_length = len(result[f\"seq_chain_{all_chain_list[0]}\"])\n",
    "        for i in range(1,chain_length+1):\n",
    "            temp_dict = {}\n",
    "            for j, chain in enumerate(all_chain_list):\n",
    "                temp_dict[chain] = [i] #needs to be a list\n",
    "            tied_positions_list.append(temp_dict)\n",
    "        my_dict[result['name']] = tied_positions_list\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4abbf3-9def-4a05-aa52-1495680e2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e266f-bb54-4452-9534-ef9c7c72f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdb(pdb_code=\"\"):\n",
    "    if pdb_code is None or pdb_code == \"\":\n",
    "        upload_dict = files.upload()\n",
    "        pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
    "        with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
    "        return \"tmp.pdb\"\n",
    "    else:\n",
    "        os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
    "        return f\"{pdb_code}.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f0ed8-5cb4-469b-896f-9f2f190cdfa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_for_csv = []\n",
    "pdb_directory = 'sample_data'\n",
    "pdb_files = [file for file in os.listdir(pdb_directory) if file.endswith('.pdb')]\n",
    "print(len(pdb_files))\n",
    "for pdb in os.listdir(pdb_directory):\n",
    "    if pdb.endswith('.pdb'):\n",
    "        pdb_path = os.path.join(pdb_directory, pdb)\n",
    "        print(pdb_path)\n",
    "    homomer = False #@param {type:\"boolean\"} #Input\n",
    "    designed_chain = \"A\" #@param {type:\"string\"} #Input\n",
    "    fixed_chain = \"\" #@param {type:\"string\"} #Input\n",
    "    if designed_chain == \"\":\n",
    "        designed_chain_list = []\n",
    "    else:\n",
    "        designed_chain_list = re.sub(\"[^A-Za-z]+\",\",\", designed_chain).split(\",\")\n",
    "\n",
    "    if fixed_chain == \"\":\n",
    "        fixed_chain_list = []\n",
    "    else:\n",
    "        fixed_chain_list = re.sub(\"[^A-Za-z]+\",\",\", fixed_chain).split(\",\")\n",
    "\n",
    "    chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
    "    num_seqs = 4 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"] {type:\"raw\"} #Input\n",
    "    num_seq_per_target = num_seqs\n",
    "\n",
    "    #@markdown - Sampling temperature for amino acids, T=0.0 means taking argmax, T>>1.0 means sample randomly.\n",
    "    sampling_temp = \"0.1\" #@param [\"0.0001\", \"0.1\", \"0.15\", \"0.2\", \"0.25\", \"0.3\", \"0.5\"] #Input\n",
    "    save_score=1                      # 0 for False, 1 for True; save score=-log_prob to npy files\n",
    "    save_probs=1                      # 0 for False, 1 for True; save MPNN predicted probabilites per position\n",
    "    score_only=1                      # 0 for False, 1 for True; score input backbone-sequence pairs\n",
    "    conditional_probs_only=0          # 0 for False, 1 for True; output conditional probabilities p(s_i given the rest of the sequence and backbone)\n",
    "    conditional_probs_only_backbone=0 # 0 for False, 1 for True; if true output conditional probabilities p(s_i given backbone)\n",
    "    \n",
    "    batch_size=1                      # Batch size; can set higher for titan, quadro GPUs, reduce this if running out of GPU memory\n",
    "    max_length=20000                  # Max sequence length\n",
    "    \n",
    "    out_folder='.'                    # Path to a folder to output sequences, e.g. /home/out/\n",
    "    jsonl_path=''                     # Path to a folder with parsed pdb into jsonl\n",
    "    omit_AAs='X'                      # Specify which amino acids should be omitted in the generated sequence, e.g. 'AC' would omit alanine and cystine.\n",
    "   \n",
    "    pssm_multi=0.0                    # A value between [0.0, 1.0], 0.0 means do not use pssm, 1.0 ignore MPNN predictions\n",
    "    pssm_threshold=0.0                # A value between -inf + inf to restric per position AAs\n",
    "    pssm_log_odds_flag=0               # 0 for False, 1 for True\n",
    "    pssm_bias_flag=0                   # 0 for False, 1 for True\n",
    "    folder_for_outputs = out_folder\n",
    "\n",
    "    NUM_BATCHES = num_seq_per_target//batch_size\n",
    "    BATCH_COPIES = batch_size\n",
    "    temperatures = [float(item) for item in sampling_temp.split()]\n",
    "    omit_AAs_list = omit_AAs\n",
    "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
    "    omit_AAs_np = np.array([AA in omit_AAs_list for AA in alphabet]).astype(np.float32)\n",
    "\n",
    "    chain_id_dict = None #Optional Input\n",
    "    fixed_positions_dict = None\n",
    "    #fixed_positions_dict = {'4y19':{'C': [3,4,5,6,7,8]}} #fix position 2,4,6,7.#The first amino acid in the chain corresponds to 1 and not PDB residues index for now\n",
    "    pssm_dict = None\n",
    "    omit_AA_dict = None\n",
    "    bias_AA_dict = None\n",
    "    tied_positions_dict = None\n",
    "    bias_by_res_dict = None\n",
    "    bias_AAs_np = np.zeros(len(alphabet))\n",
    "    pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list) #If want ca_only, then add this tag\n",
    "    dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=max_length)\n",
    "\n",
    "    chain_id_dict = {}\n",
    "    chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
    "    all_chain_list = [item[-1:] for item in list(pdb_dict_list[0]) if item[:9]=='seq_chain']\n",
    "\n",
    "    print(chain_id_dict)\n",
    "    for chain in chain_list:\n",
    "        l = len(pdb_dict_list[0][f\"seq_chain_{chain}\"])\n",
    "        #print(f\"Length of chain {chain} is {l}\")\n",
    "\n",
    "    if homomer:\n",
    "        tied_positions_dict = make_tied_positions_for_homomers(pdb_dict_list)\n",
    "    else:\n",
    "        tied_positions_dict = None\n",
    "    #@title RUN\n",
    "    __file__ = get_pdb(pdb)\n",
    "    start_time = time.time() #initialize some variables\n",
    "    total_residues = 0\n",
    "    protein_list = []\n",
    "    total_step = 0\n",
    "    #enter a validation epoch\n",
    "    with torch.no_grad():\n",
    "        print('Generating sequences...')\n",
    "    for ix, protein in enumerate(dataset_valid):\n",
    "        score_list = []\n",
    "        global_score_list = []\n",
    "        all_probs_list = []\n",
    "        all_log_probs_list = []\n",
    "        S_sample_list = []\n",
    "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
    "        #featurize the node features:\n",
    "        X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
    "        pssm_log_odds_mask = (pssm_log_odds_all > pssm_threshold).float() #1.0 for true, 0.0 for false\n",
    "        name_ = batch_clones[0]['name']\n",
    "\n",
    "        randn_1 = torch.randn(chain_M.shape, device=X.device) #if not score_only function\n",
    "        log_probs = model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
    "        mask_for_loss = mask*chain_M*chain_M_pos\n",
    "        scores = _scores(S, log_probs, mask_for_loss) #score the redesign part\n",
    "        native_score = scores.cpu().data.numpy()\n",
    "        global_scores = _scores(S, log_probs, mask) #score the whole structure-sequence\n",
    "        global_native_score = global_scores.cpu().data.numpy()\n",
    "\n",
    "        t0 = time.time()\n",
    "    for temp in temperatures:\n",
    "        for j in range(NUM_BATCHES):\n",
    "            randn_2 = torch.randn(chain_M.shape, device=X.device)\n",
    "            if tied_positions_dict == None:\n",
    "                sample_dict = model.sample(X, randn_2, S, chain_M, chain_encoding_all, residue_idx, mask=mask, temperature=temp, omit_AAs_np=omit_AAs_np, bias_AAs_np=bias_AAs_np, chain_M_pos=chain_M_pos, omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef, pssm_bias=pssm_bias, pssm_multi=pssm_multi, pssm_log_odds_flag=bool(pssm_log_odds_flag), pssm_log_odds_mask=pssm_log_odds_mask, pssm_bias_flag=bool(pssm_bias_flag), bias_by_res=bias_by_res_all)\n",
    "                S_sample = sample_dict[\"S\"] \n",
    "            else:\n",
    "                sample_dict = model.tied_sample(X, randn_2, S, chain_M, chain_encoding_all, residue_idx, mask=mask, temperature=temp, omit_AAs_np=omit_AAs_np, bias_AAs_np=bias_AAs_np, chain_M_pos=chain_M_pos, omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef, pssm_bias=pssm_bias, pssm_multi=pssm_multi, pssm_log_odds_flag=bool(pssm_log_odds_flag), pssm_log_odds_mask=pssm_log_odds_mask, pssm_bias_flag=bool(pssm_bias_flag), tied_pos=tied_pos_list_of_lists_list[0], tied_beta=tied_beta, bias_by_res=bias_by_res_all)\n",
    "            # Compute scores\n",
    "                S_sample = sample_dict[\"S\"]\n",
    "            log_probs = model(X, S_sample, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_2, use_input_decoding_order=True, decoding_order=sample_dict[\"decoding_order\"])\n",
    "            mask_for_loss = mask*chain_M*chain_M_pos\n",
    "            scores = _scores(S_sample, log_probs, mask_for_loss)\n",
    "            scores = scores.cpu().data.numpy()\n",
    "\n",
    "            global_scores = _scores(S_sample, log_probs, mask) #score the whole structrue-sequence\n",
    "            global_scores = global_scores.cpu().data.numpy()\n",
    "\n",
    "            all_probs_list.append(sample_dict[\"probs\"].cpu().data.numpy())\n",
    "            all_log_probs_list.append(log_probs.cpu().data.numpy())\n",
    "            S_sample_list.append(S_sample.cpu().data.numpy())\n",
    "            for b_ix in range(BATCH_COPIES):\n",
    "                masked_chain_length_list = masked_chain_length_list_list[b_ix]\n",
    "                masked_list = masked_list_list[b_ix]\n",
    "                seq_recovery_rate = torch.sum(torch.sum(torch.nn.functional.one_hot(S[b_ix], 21)*torch.nn.functional.one_hot(S_sample[b_ix], 21),axis=-1)*mask_for_loss[b_ix])/torch.sum(mask_for_loss[b_ix])\n",
    "                seq = _S_to_seq(S_sample[b_ix], chain_M[b_ix])\n",
    "                score = scores[b_ix]\n",
    "                score_list.append(score)\n",
    "                global_score = global_scores[b_ix]\n",
    "                global_score_list.append(global_score)\n",
    "                native_seq = _S_to_seq(S[b_ix], chain_M[b_ix])\n",
    "                if b_ix == 0 and j==0 and temp==temperatures[0]:\n",
    "                    start = 0\n",
    "                    end = 0\n",
    "                    list_of_AAs = []\n",
    "                    for mask_l in masked_chain_length_list:\n",
    "                        end += mask_l\n",
    "                        list_of_AAs.append(native_seq[start:end])\n",
    "                        start = end\n",
    "                    native_seq = \"\".join(list(np.array(list_of_AAs)[np.argsort(masked_list)]))\n",
    "                    l0 = 0\n",
    "                    for mc_length in list(np.array(masked_chain_length_list)[np.argsort(masked_list)])[:-1]:\n",
    "                        l0 += mc_length\n",
    "                        native_seq = native_seq[:l0] + '/' + native_seq[l0:]\n",
    "                        l0 += 1\n",
    "                    sorted_masked_chain_letters = np.argsort(masked_list_list[0])\n",
    "                    print_masked_chains = [masked_list_list[0][i] for i in sorted_masked_chain_letters]\n",
    "                    sorted_visible_chain_letters = np.argsort(visible_list_list[0])\n",
    "                    print_visible_chains = [visible_list_list[0][i] for i in sorted_visible_chain_letters]\n",
    "                    native_score_print = np.format_float_positional(np.float32(native_score.mean()), unique=False, precision=4)\n",
    "                    global_native_score_print = np.format_float_positional(np.float32(global_native_score.mean()), unique=False, precision=4)\n",
    "                    IEDBID = name_\n",
    "                    line = '>{}, score={}, fixed_chains={}, designed_chains={}, model_name={}, seed={}\\n{}\\n'.format(IEDBID, native_score_print, print_visible_chains, print_masked_chains, model_name, seed, native_seq)\n",
    "                    #print(line.rstrip())\n",
    "                start = 0\n",
    "                end = 0\n",
    "                list_of_AAs = []\n",
    "                for mask_l in masked_chain_length_list:\n",
    "                    end += mask_l\n",
    "                    list_of_AAs.append(seq[start:end])\n",
    "                    start = end\n",
    "\n",
    "                seq = \"\".join(list(np.array(list_of_AAs)[np.argsort(masked_list)]))\n",
    "                l0 = 0\n",
    "                for mc_length in list(np.array(masked_chain_length_list)[np.argsort(masked_list)])[:-1]:\n",
    "                    l0 += mc_length\n",
    "                    seq = seq[:l0] + '/' + seq[l0:]\n",
    "                    l0 += 1\n",
    "                score_print = np.format_float_positional(np.float32(score), unique=False, precision=4)\n",
    "                global_score_print = np.format_float_positional(np.float32(global_score), unique=False, precision=4)\n",
    "                seq_rec_print = np.format_float_positional(np.float32(seq_recovery_rate.detach().cpu().numpy()), unique=False, precision=4)\n",
    "                sample_number = j*BATCH_COPIES+b_ix+1\n",
    "                line = '>T={}, sample={}, score={}, global_score={}, seq_recovery={}\\n{}\\n'.format(temp,sample_number,score_print,global_score_print, seq_rec_print,seq)\n",
    "                #print(line.rstrip())\n",
    "                iedb_id_csv = IEDBID\n",
    "                seq_csv = seq\n",
    "                seq_rec_csv = seq_rec_print\n",
    "                data_for_csv.append({\n",
    "                \"IEDBID\": iedb_id_csv,\n",
    "                \"sequences\": seq_csv,\n",
    "                \"sequence recovery\": seq_rec_csv,\n",
    "                })\n",
    "    all_probs_concat = np.concatenate(all_probs_list)\n",
    "    all_log_probs_concat = np.concatenate(all_log_probs_list)\n",
    "    S_sample_concat = np.concatenate(S_sample_list)\n",
    "    t1 = time.time()\n",
    "    dt = round(float(t1-t0), 4)\n",
    "    num_seqs = len(temperatures)*NUM_BATCHES*BATCH_COPIES\n",
    "    total_length = X.shape[1]\n",
    "    df = pd.DataFrame(data_for_csv)\n",
    "    output_csv_path = \"output_sequences_sample_data.csv\"\n",
    "    df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ed6d7-b880-4cad-aefb-dfdb05361550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output csv only contains the redesigned sequences, do not include the original input sequence.\n",
    "df = pd.read_csv('output_sequences_sample_data.csv')\n",
    "average_recovery = df.groupby('IEDBID')['sequence recovery'].mean().reset_index()\n",
    "average_recovery.rename(columns={'sequence recovery': 'average sequence recovery'}, inplace=True)\n",
    "print(average_recovery)\n",
    "average_recovery.to_csv('average_sequence_recovery_sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0736ac-e67f-4b3a-a349-f0e16f72519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695903a7-cd19-4927-9f8b-d8f1f203e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('average_sequence_recovery_sample_data.csv')\n",
    "stats = df['average sequence recovery'].describe()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df.index, df['average sequence recovery'], alpha=0.6)\n",
    "plt.title('Scatter Plot of Average Sequence Recovery')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Average Sequence Recovery')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('average_sequence_recovery_plot_sample_data.png', dpi=300)  # Adjust dpi for higher resolution\n",
    "\n",
    "plt.show()\n",
    "\n",
    "mean_recovery = df['average sequence recovery'].mean()\n",
    "median_recovery = df['average sequence recovery'].median()\n",
    "std_recovery = df['average sequence recovery'].std()\n",
    "min_recovery = df['average sequence recovery'].min()\n",
    "max_recovery = df['average sequence recovery'].max()\n",
    "print(f\"Mean average sequence recovery: {mean_recovery}\")\n",
    "print(f\"Median average sequence recovery: {median_recovery}\")\n",
    "print(f\"Standard Deviation of average sequence recovery: {std_recovery}\")\n",
    "print(f\"Min average sequence recovery: {min_recovery}\")\n",
    "print(f\"Max average sequence recovery: {max_recovery}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epim2",
   "language": "python",
   "name": "epim2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
