{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630d4d3-7414-4dec-a179-16b4b3c907d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Try my epitope\n",
    "import json, time, os, sys, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def8162-020c-43a3-9235-72fb6c7cb657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Setup Model\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split, Subset\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os.path\n",
    "from protein_mpnn_utils import loss_nll, loss_smoothed, gather_edges, gather_nodes, gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq, tied_featurize, parse_PDB\n",
    "from protein_mpnn_utils import StructureDataset, StructureDatasetPDB, ProteinMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6db185-5be3-4abf-a6e9-fe57891b64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "model_name = \"128_earlystop\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e7b8b-3e89-4045-a8de-706780043894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5b1eb-9f36-4356-a41c-fd8b42712026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#seed=int(np.random.randint(0, high=999, size=1, dtype=int)[0]) #write by my own\n",
    "seed = 37\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0a128-805b-46aa-803d-a0a45f39eb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone_noise=0.00               # Standard deviation of Gaussian noise to add to backbone atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ea5b1-c583-4726-930a-f9651b61ccd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366c1e9-a315-4ba3-8aa9-07ce92cd57ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_model_weights='.'          \n",
    "hidden_dim = 128\n",
    "num_layers = 3 \n",
    "model_folder_path = path_to_model_weights\n",
    "if model_folder_path[-1] != '/':\n",
    "    model_folder_path = model_folder_path + '/'\n",
    "checkpoint_path = model_folder_path + f'{model_name}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd3c8d-7e7a-4d46-a9a8-5b5f7d570031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device) \n",
    "print('Number of edges:', checkpoint['num_edges'])\n",
    "noise_level_print = checkpoint['noise_level']\n",
    "print(f'Training noise level: {noise_level_print}A')\n",
    "model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
    "model.to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920958d-98b3-415d-9b53-17283e335a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_tied_positions_for_homomers(pdb_dict_list):\n",
    "    my_dict = {}\n",
    "    for result in pdb_dict_list:\n",
    "        all_chain_list = sorted([item[-1:] for item in list(result) if item[:9]=='seq_chain']) #A, B, C, ...\n",
    "        tied_positions_list = []\n",
    "        chain_length = len(result[f\"seq_chain_{all_chain_list[0]}\"])\n",
    "        for i in range(1,chain_length+1):\n",
    "            temp_dict = {}\n",
    "            for j, chain in enumerate(all_chain_list):\n",
    "                temp_dict[chain] = [i] #needs to be a list\n",
    "            tied_positions_list.append(temp_dict)\n",
    "        my_dict[result['name']] = tied_positions_list\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73179582-a5b4-4182-b370-c4c7c1d1b21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abce3d-b68f-4755-9d71-8a469e97eebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pdb(pdb_code=\"\"):\n",
    "  if pdb_code is None or pdb_code == \"\":\n",
    "    upload_dict = files.upload()\n",
    "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
    "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
    "    return \"tmp.pdb\"\n",
    "  else:\n",
    "    os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
    "    return f\"{pdb_code}.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9356f-cc3a-418d-9288-bbbbf6230ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdb='4p57' \n",
    "print(get_pdb(pdb))\n",
    "pdb_path = './4p57.pdb' #Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51126d3e-15c8-4bde-a71e-31cb45569949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "homomer = False #@param {type:\"boolean\"} #Input\n",
    "designed_chain = \"B\" #@param {type:\"string\"} #Input: open the pdb file to see the chain ID\n",
    "fixed_chain = \"\" #@param {type:\"string\"} #Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf72713-48de-41b5-ba52-9f6c53ab108d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if designed_chain == \"\":\n",
    "  designed_chain_list = []\n",
    "else:\n",
    "  designed_chain_list = re.sub(\"[^A-Za-z]+\",\",\", designed_chain).split(\",\")\n",
    "\n",
    "if fixed_chain == \"\":\n",
    "  fixed_chain_list = []\n",
    "else:\n",
    "  fixed_chain_list = re.sub(\"[^A-Za-z]+\",\",\", fixed_chain).split(\",\")\n",
    "\n",
    "chain_list = list(set(designed_chain_list + fixed_chain_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338cc27-19c6-429c-8873-dedd7ef9463a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown - specified which chain(s) to design and which chain(s) to keep fixed. \n",
    "#@markdown   Use comma:`A,B` to specifiy more than one chain\n",
    "\n",
    "#chain = \"J\" #@param {type:\"string\"}\n",
    "#pdb_path_chains = chain\n",
    "##@markdown - Define which chain to redesign\n",
    "\n",
    "#@markdown ### Design Options\n",
    "num_seqs = 8 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"] {type:\"raw\"} #Input\n",
    "num_seq_per_target = num_seqs\n",
    "\n",
    "#@markdown - Sampling temperature for amino acids, T=0.0 means taking argmax, T>>1.0 means sample randomly.\n",
    "sampling_temp = \"0.1\" #@param [\"0.0001\", \"0.1\", \"0.15\", \"0.2\", \"0.25\", \"0.3\", \"0.5\"] #Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef4e69-6a58-4dfd-a057-160c3b9c4076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_score=1                      # 0 for False, 1 for True; save score=-log_prob to npy files\n",
    "save_probs=1                      # 0 for False, 1 for True; save MPNN predicted probabilites per position\n",
    "score_only=1                      # 0 for False, 1 for True; score input backbone-sequence pairs\n",
    "conditional_probs_only=0          # 0 for False, 1 for True; output conditional probabilities p(s_i given the rest of the sequence and backbone)\n",
    "conditional_probs_only_backbone=0 # 0 for False, 1 for True; if true output conditional probabilities p(s_i given backbone)\n",
    "    \n",
    "batch_size=1                      # Batch size; can set higher for titan, quadro GPUs, reduce this if running out of GPU memory\n",
    "max_length=20000                  # Max sequence length\n",
    "    \n",
    "out_folder='.'                    # Path to a folder to output sequences, e.g. /home/out/\n",
    "jsonl_path=''                     # Path to a folder with parsed pdb into jsonl\n",
    "omit_AAs='X'                      # Specify which amino acids should be omitted in the generated sequence, e.g. 'AC' would omit alanine and cystine.\n",
    "   \n",
    "pssm_multi=0.0                    # A value between [0.0, 1.0], 0.0 means do not use pssm, 1.0 ignore MPNN predictions\n",
    "pssm_threshold=0.0                # A value between -inf + inf to restric per position AAs\n",
    "pssm_log_odds_flag=0               # 0 for False, 1 for True\n",
    "pssm_bias_flag=0                   # 0 for False, 1 for True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c25134-79b8-4806-bc4b-506fb7923c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_for_outputs = out_folder\n",
    "\n",
    "NUM_BATCHES = num_seq_per_target//batch_size\n",
    "BATCH_COPIES = batch_size\n",
    "temperatures = [float(item) for item in sampling_temp.split()]\n",
    "omit_AAs_list = omit_AAs\n",
    "alphabet = 'ACDEFGHIKLMNPQRSTVWYX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a25f0-7426-48bc-8965-495ffa6eb1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "omit_AAs_np = np.array([AA in omit_AAs_list for AA in alphabet]).astype(np.float32)\n",
    "\n",
    "chain_id_dict = None #Optional Input\n",
    "fixed_positions_dict = None #{'melanoma':{'A': [1,2,9,10,13,14,15,16]}} ###mask positions 2,3,8,9,10\n",
    "pssm_dict = None\n",
    "omit_AA_dict = None\n",
    "bias_AA_dict = None\n",
    "tied_positions_dict = None\n",
    "bias_by_res_dict = None\n",
    "bias_AAs_np = np.zeros(len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d05c9-f3bd-471f-ba6f-aaa8a6f72319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list) #If want ca_only, then add this tag\n",
    "dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=max_length)\n",
    "\n",
    "chain_id_dict = {}\n",
    "chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
    "all_chain_list = [item[-1:] for item in list(pdb_dict_list[0]) if item[:9]=='seq_chain']\n",
    "\n",
    "print(chain_id_dict)\n",
    "for chain in chain_list:\n",
    "  l = len(pdb_dict_list[0][f\"seq_chain_{chain}\"])\n",
    "  print(f\"Length of chain {chain} is {l}\")\n",
    "\n",
    "if homomer:\n",
    "  tied_positions_dict = make_tied_positions_for_homomers(pdb_dict_list)\n",
    "else:\n",
    "  tied_positions_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12805a5b-ab2d-4946-a55e-7af587beaf47",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "__file__ = get_pdb(pdb)\n",
    "start_time = time.time() #initialize some variables\n",
    "total_residues = 0\n",
    "protein_list = []\n",
    "total_step = 0\n",
    "#enter a validation epoch\n",
    "with torch.no_grad():\n",
    "  print('Generating sequences...')\n",
    "  for ix, protein in enumerate(dataset_valid):\n",
    "    score_list = []\n",
    "    global_score_list = []\n",
    "    all_probs_list = []\n",
    "    all_log_probs_list = []\n",
    "    S_sample_list = []\n",
    "    batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
    "    #featurize the node features:\n",
    "    X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
    "    pssm_log_odds_mask = (pssm_log_odds_all > pssm_threshold).float() #1.0 for true, 0.0 for false\n",
    "    name_ = batch_clones[0]['name']\n",
    "\n",
    "    randn_1 = torch.randn(chain_M.shape, device=X.device) #if not score_only function\n",
    "    log_probs = model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
    "    mask_for_loss = mask*chain_M*chain_M_pos\n",
    "    scores = _scores(S, log_probs, mask_for_loss) #score the redesign part\n",
    "    native_score = scores.cpu().data.numpy()\n",
    "    global_scores = _scores(S, log_probs, mask) #score the whole structure-sequence\n",
    "    global_native_score = global_scores.cpu().data.numpy()\n",
    "    #score_file = base_folder + '/scores/' + batch_clones[0]['name'] + '.npz'\n",
    "    #probs_file = base_folder + '/probs/' + batch_clones[0]['name'] + '.npz'\n",
    "      \n",
    "    t0 = time.time()\n",
    "    for temp in temperatures:\n",
    "        for j in range(NUM_BATCHES):\n",
    "            randn_2 = torch.randn(chain_M.shape, device=X.device)\n",
    "            if tied_positions_dict == None:\n",
    "                sample_dict = model.sample(X, randn_2, S, chain_M, chain_encoding_all, residue_idx, mask=mask, temperature=temp, omit_AAs_np=omit_AAs_np, bias_AAs_np=bias_AAs_np, chain_M_pos=chain_M_pos, omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef, pssm_bias=pssm_bias, pssm_multi=pssm_multi, pssm_log_odds_flag=bool(pssm_log_odds_flag), pssm_log_odds_mask=pssm_log_odds_mask, pssm_bias_flag=bool(pssm_bias_flag), bias_by_res=bias_by_res_all)\n",
    "                S_sample = sample_dict[\"S\"] \n",
    "            else:\n",
    "                sample_dict = model.tied_sample(X, randn_2, S, chain_M, chain_encoding_all, residue_idx, mask=mask, temperature=temp, omit_AAs_np=omit_AAs_np, bias_AAs_np=bias_AAs_np, chain_M_pos=chain_M_pos, omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef, pssm_bias=pssm_bias, pssm_multi=pssm_multi, pssm_log_odds_flag=bool(pssm_log_odds_flag), pssm_log_odds_mask=pssm_log_odds_mask, pssm_bias_flag=bool(pssm_bias_flag), tied_pos=tied_pos_list_of_lists_list[0], tied_beta=tied_beta, bias_by_res=bias_by_res_all)\n",
    "            # Compute scores\n",
    "                S_sample = sample_dict[\"S\"]\n",
    "            log_probs = model(X, S_sample, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_2, use_input_decoding_order=True, decoding_order=sample_dict[\"decoding_order\"])\n",
    "            mask_for_loss = mask*chain_M*chain_M_pos\n",
    "            scores = _scores(S_sample, log_probs, mask_for_loss)\n",
    "            scores = scores.cpu().data.numpy()\n",
    "            \n",
    "            global_scores = _scores(S_sample, log_probs, mask) #score the whole structrue-sequence\n",
    "            global_scores = global_scores.cpu().data.numpy()\n",
    "            \n",
    "            all_probs_list.append(sample_dict[\"probs\"].cpu().data.numpy())\n",
    "            all_log_probs_list.append(log_probs.cpu().data.numpy())\n",
    "            S_sample_list.append(S_sample.cpu().data.numpy())\n",
    "            for b_ix in range(BATCH_COPIES):\n",
    "                masked_chain_length_list = masked_chain_length_list_list[b_ix]\n",
    "                masked_list = masked_list_list[b_ix]\n",
    "                seq_recovery_rate = torch.sum(torch.sum(torch.nn.functional.one_hot(S[b_ix], 21)*torch.nn.functional.one_hot(S_sample[b_ix], 21),axis=-1)*mask_for_loss[b_ix])/torch.sum(mask_for_loss[b_ix])\n",
    "                seq = _S_to_seq(S_sample[b_ix], chain_M[b_ix])\n",
    "                score = scores[b_ix]\n",
    "                score_list.append(score)\n",
    "                global_score = global_scores[b_ix]\n",
    "                global_score_list.append(global_score)\n",
    "                native_seq = _S_to_seq(S[b_ix], chain_M[b_ix])\n",
    "                if b_ix == 0 and j==0 and temp==temperatures[0]:\n",
    "                    start = 0\n",
    "                    end = 0\n",
    "                    list_of_AAs = []\n",
    "                    for mask_l in masked_chain_length_list:\n",
    "                        end += mask_l\n",
    "                        list_of_AAs.append(native_seq[start:end])\n",
    "                        start = end\n",
    "                    native_seq = \"\".join(list(np.array(list_of_AAs)[np.argsort(masked_list)]))\n",
    "                    l0 = 0\n",
    "                    for mc_length in list(np.array(masked_chain_length_list)[np.argsort(masked_list)])[:-1]:\n",
    "                        l0 += mc_length\n",
    "                        native_seq = native_seq[:l0] + '/' + native_seq[l0:]\n",
    "                        l0 += 1\n",
    "                    sorted_masked_chain_letters = np.argsort(masked_list_list[0])\n",
    "                    print_masked_chains = [masked_list_list[0][i] for i in sorted_masked_chain_letters]\n",
    "                    sorted_visible_chain_letters = np.argsort(visible_list_list[0])\n",
    "                    print_visible_chains = [visible_list_list[0][i] for i in sorted_visible_chain_letters]\n",
    "                    native_score_print = np.format_float_positional(np.float32(native_score.mean()), unique=False, precision=4)\n",
    "                    global_native_score_print = np.format_float_positional(np.float32(global_native_score.mean()), unique=False, precision=4)\n",
    "                    line = '>{}, score={}, global_score={}, fixed_chains={}, designed_chains={}, model_name={}, seed={}\\n{}\\n'.format(name_, native_score_print, global_native_score_print, print_visible_chains, print_masked_chains, model_name, seed, native_seq)\n",
    "                    print(line.rstrip())\n",
    "                start = 0\n",
    "                end = 0\n",
    "                list_of_AAs = []\n",
    "                for mask_l in masked_chain_length_list:\n",
    "                    end += mask_l\n",
    "                    list_of_AAs.append(seq[start:end])\n",
    "                    start = end\n",
    "\n",
    "                seq = \"\".join(list(np.array(list_of_AAs)[np.argsort(masked_list)]))\n",
    "                l0 = 0\n",
    "                for mc_length in list(np.array(masked_chain_length_list)[np.argsort(masked_list)])[:-1]:\n",
    "                    l0 += mc_length\n",
    "                    seq = seq[:l0] + '/' + seq[l0:]\n",
    "                    l0 += 1\n",
    "                score_print = np.format_float_positional(np.float32(score), unique=False, precision=4)\n",
    "                global_score_print = np.format_float_positional(np.float32(global_score), unique=False, precision=4)\n",
    "                seq_rec_print = np.format_float_positional(np.float32(seq_recovery_rate.detach().cpu().numpy()), unique=False, precision=4)\n",
    "                sample_number = j*BATCH_COPIES+b_ix+1\n",
    "                line = '>T={}, sample={}, score={}, global_score={}, seq_recovery={}\\n{}\\n'.format(temp,sample_number,score_print,global_score_print, seq_rec_print,seq)\n",
    "                print(line.rstrip())\n",
    "\n",
    "all_probs_concat = np.concatenate(all_probs_list)\n",
    "all_log_probs_concat = np.concatenate(all_log_probs_list)\n",
    "S_sample_concat = np.concatenate(S_sample_list)\n",
    "t1 = time.time()\n",
    "dt = round(float(t1-t0), 4)\n",
    "num_seqs = len(temperatures)*NUM_BATCHES*BATCH_COPIES\n",
    "total_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce5cd3-0098-4c22-a7c9-eb176e9bb290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown ### Amino acid probabilties\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = np.exp(all_log_probs_concat).mean(0).T\n",
    "alphabet = list(alphabet)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(data, aspect=\"auto\", cmap=\"viridis\")\n",
    "ax.set_xlabel(\"positions\")\n",
    "ax.set_ylabel(\"amino acids\")\n",
    "ax.set_yticks(range(len(alphabet))) \n",
    "ax.set_yticklabels(alphabet)         \n",
    "ax.xaxis.tick_top()                  \n",
    "ax.xaxis.set_label_position('top') \n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label(\"probability\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb3fc9-51d1-4661-9b98-5b41c2f7d327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown ### Sampling temperature adjusted amino acid probabilties\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = all_probs_concat.mean(0).T \n",
    "alphabet = list(alphabet)         \n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(data, aspect=\"auto\", cmap=\"viridis\")  \n",
    "ax.set_xlabel(\"positions\")\n",
    "ax.set_ylabel(\"amino acids\")\n",
    "ax.set_yticks(range(len(alphabet))) \n",
    "ax.set_yticklabels(alphabet)      \n",
    "ax.xaxis.tick_top()                 \n",
    "ax.xaxis.set_label_position('top')  \n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label(\"probability\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a32ee1-5f4f-43e6-a1cb-e49001e95a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epim2",
   "language": "python",
   "name": "epim2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
